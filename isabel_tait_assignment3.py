# -*- coding: utf-8 -*-
"""Isabel_Tait_Assignment3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJCwAKJH03xZZKAV0ZocoAufwmwsp2C-
"""

import numpy as np

"""Assignment 3
Isabel Tait 
Z23426504
https://colab.research.google.com/drive/1bJCwAKJH03xZZKAV0ZocoAufwmwsp2C-
"""

class NeuralNetwork():
  def init(self, learning_r):
    self.learning_r=learning_r;
    # 3x1 Weight matrix 
    self.weights=[1 for i in range(3)]
    self.training_cost=0
    return self.learning_r, self.weights, self.training_cost

  def forward_propagation(self, inputs, weights):
     self.learning_rate,self.weights, self.training_cost= NeuralNetwork().init(0.1)
     self.v = weights[2]
     for i in range(len(inputs)-1):
      self.v+=inputs[i]*weights[i]
     return self.v

  def train(self, inputs_train, labels_train, num_train_epochs): #This function alsosavesthe weights and costs at every epoch to the history variable.
      self.l_rate,self.weights, self.training_cost = self.init(0.1)
      self.error_for_each_input_row=[]
      self.input_error_squared=0
      self.predicted_label=[]
      self.error_sum=[]
      

      for self.epoch in range(num_train_epochs): 
        self.input_errors_sum=0 
        self.input_error_squared=0 
        self.input_errors=0  
        self.firstWeight_update_average=0
        self.secondWeight_update_average=0 
        self.training_cost=0
        training_cost_list=[]
        for self.row in inputs_train:
          self.hello = NeuralNetwork().forward_propagation(self.row, self.weights)
          #print("This is predicted labels ",self.hello)
          
          self.error_for_each_input_row.append(self.hello-self.row[2])  #labels_train are desired labels 
          self.input_errors=self.hello-self.row[2]    #DO NOT CHANGE THIS BLOCK 
          self.input_errors_sum+=self.input_errors

          
          self.input_error_squared+=((self.hello-self.row[2])**2)
          self.firstWeight_update_average+=self.input_errors*self.row[0]/len(inputs_train)
          self.secondWeight_update_average+=self.input_errors*self.row[1]/len(inputs_train)

        self.training_cost+=(self.input_error_squared/len(inputs_train))
        self.weights[0]=self.weights[0]-(self.firstWeight_update_average*self.l_rate)
        self.weights[1]=self.weights[1]-(self.secondWeight_update_average*self.l_rate)
        self.weights[2]=self.weights[2]-((self.input_errors_sum/len(inputs_train))*self.l_rate) #bias update
        print("epoch ",self.epoch+1,":") 
        print("Training Cost: ",self.training_cost)
        training_cost_list.append(self.training_cost)
        print("Updated first weight ", self.weights[0])
        print("Updated second weight ", self.weights[1])
        print("Updated bias ",self.weights[2])
        print(" ")
        return training_cost_list

dataset_inputs=[ [1,1,1], [1,0,1], [0,1,-1], [-1,-1,-1], [0.5,3,1], [0.7,2,1], [-1,0,-1], [-1,1,-1], [2,0,1], [-2,-1,-1] ] #desired label is first element of each list
dataset_labels=[1,1,-1,-1,1,1,-1,-1,1,-1]

NeuralNetwork().train(dataset_inputs,dataset_labels,50)

import matplotlib.pyplot as plt
from sympy.solvers import solve
from sympy import Symbol


plt.xlabel('X1')
plt.ylabel('X2')
plt.title('Data Points')
plt.axis([-2.6,2.6,-3.5,3.5])

for m in range(len(dataset_inputs)):
  if dataset_inputs[m][2]==-1:
    plt.plot(dataset_inputs[m][0], dataset_inputs[m][1], "ro",label="0", color = "red")#1
  else:  
    plt.plot(dataset_inputs[m][0], dataset_inputs[m][1], "d", label="1", color="yellow")#-1
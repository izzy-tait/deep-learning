# -*- coding: utf-8 -*-
"""Isabel_Tait_Assignment_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IQuLGaId5KLPvA3GW8jfRU06K0fkNMYX

Isabel Tait
Z23426504
Assignment 2
https://colab.research.google.com/drive/1IQuLGaId5KLPvA3GW8jfRU06K0fkNMYX
"""

from keras.datasets import mnist
import matplotlib.pyplot as plt
import numpy as np 
from random import randint

(x_train, y_train), (x_test, y_test) = mnist.load_data()


#Selecting 0's and 1's from datset and putting them into training set 
train_filter = np.where((y_train == 0 ) | (y_train == 1))
test_filter = np.where((y_test == 0) | (y_test == 1))

x_new_train, y_new_train = x_train[train_filter], y_train[train_filter]
x_new_test, y_new_test= x_test[test_filter], y_test[test_filter]

from sklearn.model_selection import train_test_split
#(x_alt_train,x_alt_valid) = train_test_split(x_new_train,test_size = 0.2) #splitting training set into training and validation sets
#(y_alt_train, y_alt_valid) = train_test_split(y_new_train, test_size=0.2)
print("The length of training data is" )
print(len(x_new_train))
print("The length of testing data is")
print(len(x_new_test))
print("The number of 1's and 0's images is")
print(12665+2115)

import numpy as np
import matplotlib.pyplot as plt

meanArray=[]   #array for pixel averages of 3x3 center
new_test_set=[]

for i in range(len(x_new_train)): #was x_alt_train
  x = x_new_train[i][12:15,12:15].mean()
  y = y_new_train[i]
  meanArray.append([x,y])

for r in range(len(x_new_test)): #MAKING TESTING SET TWO DIMENSION AS WELL
  g = x_new_test[r][12:15,12:15].mean()
  h = y_new_test[r]
  new_test_set.append([g,h])



print(meanArray[5]) #when 0.0, gives label as 1, when image>0, gives me label as 0
plt.imshow(x_new_train[5], cmap='gray')  #so 0.0 means black?

import random 
import matplotlib.pyplot as plt
import numpy as np

random500=[]
x_alt_train=[]

random.shuffle(meanArray)  #shuffle array 

for j in range(500):
   random500.append(meanArray[j])  #select first 500 of shuffled array



for t in range(500, len(x_new_train)):   #removing validation set from training set  
   x_alt_train.append(meanArray[t])
  

#print(random500[0])
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Attribute Plot')
plt.axis([0,500,0,256])

for m in range(500):
  if random500[m][1]==0:
    plt.plot(m, random500[m][0], "ro",label=str(), color = "red")#0
  else:  
    plt.plot(m, random500[m][0], "d", label=str(), color="yellow")#1

#plt.legend()
plt.show()

print(random500)

print("Based on looking at the plot, the threshold seems to be that if attribute>40, then image is a '1'")
#print(len(random500)) #validation
#print(len(x_alt_train))
#print(len(new_test_set))

valid_count=0

for e in range(len(random500)):
  if random500[e][1]==0 and random500[e][0]<40:
     valid_count=valid_count+1
  elif random500[e][1]==1 and random500[e][0]>=40:
     valid_count=valid_count+1

valid_accuracy=valid_count/(len(random500))
print("The accuracy of the validation set is",valid_accuracy)

train_count=0
for w in range(len(x_alt_train)):
  if x_alt_train[w][1]==0 and x_alt_train[w][0]<40:
     train_count=train_count+1
  elif x_alt_train[w][1]==1 and x_alt_train[w][0]>=40:
     train_count=train_count+1

train_accuracy=train_count/(len(x_alt_train))   
print("The accuracy of the training set is",train_accuracy)  

test_count=0
for q in range(len(new_test_set)):
  if new_test_set[q][1]==0 and new_test_set[q][0]<40:
    test_count=test_count+1
  elif new_test_set[q][1]==1 and new_test_set[q][0]>=40:
    test_count=test_count+1

test_accuracy=test_count/(len(new_test_set))
print("The accuracy of the testing set is",test_accuracy)

class NeuralNetwork():

  def init(self):
    self.learning_rate=1
    # 3x1 Weight matrix 
    self.weights=[0 for i in range(3)]
    #self.weight_matrix= 2 * np.random.random((3, 1))-1
    return self.weights, self.learning_rate
    
  def hard_limiter(self,x):  #that performs the hard-limiter activation on the nx1 vector x.
    #x is the output  
    return 1 if x>=0 else 0

   
  def forward_propagation(self, inputs, weights):  #multiplying the inputs by the neuron weights and then passingthe output through the hard_limiteractivation function.
    #self.inputs * self.weight_matrix[]
    self.v = weights[2]
    for i in range(len(inputs)-1):
      self.v+=inputs[i]*weights[i]
    return self.hard_limiter(self.v)

  def pred(self, inputs, weights):
    pred = NeuralNetwork().forward_propagation(inputs,weights)
    return pred

  def train(self, inputs, num_train_iterations):  #def train(self, inputs, num_train_iterations):
    self.weights,self.l_rate = self.init()
    for self.epoch in range(num_train_iterations):
      self.sum_error = 0
      self.predictedLabels=[]
      for self.row in inputs:
          self.pred = NeuralNetwork().pred(self.row,self.weights)
          self.predictedLabels.append(self.pred)
          #self.pred=NeuralNetwork().pred(self.inputs, self.weights)
          self.error = self.row[2] - self.pred
          #self.error=self.labels[-1]-self.pred
          self.sum_error += self.error**2
          self.weights[2] = self.weights[2] + self.l_rate * self.error
          for i in range(len(self.row)-1):
            self.weights[i] = self.weights[i] + self.l_rate * self.error * self.row[i]
      print('>epoch = %d, lrate = %.3f, error = %.3f' % (self.epoch, self.l_rate, self.sum_error))
    return self.weights, self.predictedLabels
    #that performs the perceptron learning rule for num_train_iterationstimes using the inputs and labels.

dataset = [[1,1,1],[1,0,1],[0,1,0],[-1,-1,0],[-1,0,0],[-1,1,0]]

weights, pred = NeuralNetwork().train(dataset,10)   #train(inputs, labels, 100)

print("The weights after 10 iterations are:",weights)
print("The predictin values are 10 iterations are:",pred)

import matplotlib.pyplot as plt
from sympy.solvers import solve
from sympy import Symbol


plt.xlabel('X1')
plt.ylabel('X2')
plt.title('Data Points')
plt.axis([-2,2,-2,2])

for m in range(len(pred)):
  if pred[m]==0:
    plt.plot(dataset[m][0], dataset[m][1], "ro",label="0", color = "red")#0
  else:  
    plt.plot(dataset[m][0], dataset[m][1], "d", label="1", color="yellow")#1


x=Symbol('x')
classifierLine=solve(x*weights[0]+weights[2], x)
print("Classifier Line: ",classifierLine)

plt.axvline(classifierLine)

#plt.legend()
plt.show()

altDataSet=[[2,0,1], [2,1,0], [0,0,1], [-2,0,0]]
altweights=[0 for i in range(3)]
altpred=[]

for row in altDataSet:
  altpred.append(NeuralNetwork().pred(row,altweights))

print("The predictions for these data points are: ",altpred)